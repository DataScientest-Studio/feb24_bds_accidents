{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.metrics import classification_report, make_scorer, recall_score\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from global_vars import chargement_train_test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Réseau \n",
    "**Tests comparatif, couches, optimizer epochs, validation split etc. En gros un grid search à la mano pour un soucis de rapidité d'execution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = chargement_train_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = make_scorer(recall_score, average=\"macro\", labels=[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential(\n",
    "        [\n",
    "            Dense(\n",
    "                200,\n",
    "                activation=\"relu\",\n",
    "                kernel_initializer=\"he_normal\",\n",
    "                input_shape=(48,),\n",
    "            ),\n",
    "            Dense(100, activation=\"relu\"),\n",
    "            Dense(4, activation=\"softmax\"),\n",
    "        ]\n",
    "    )\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=Adam())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(\n",
    "    build_fn=create_model, epochs=10, batch_size=32, validation_split=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\estel\\Documents\\Apprentissage\\Datascientest\\Projet\\feb24_bds_accidents\\venv\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Users\\estel\\Documents\\Apprentissage\\Datascientest\\Projet\\feb24_bds_accidents\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1.1881 - val_loss: 1.1068\n",
      "Epoch 2/10\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.0794 - val_loss: 1.1039\n",
      "Epoch 3/10\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1.0540 - val_loss: 1.0936\n",
      "Epoch 4/10\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.0399 - val_loss: 1.0941\n",
      "Epoch 5/10\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.0293 - val_loss: 1.0924\n",
      "Epoch 6/10\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.0260 - val_loss: 1.0945\n",
      "Epoch 7/10\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1.0078 - val_loss: 1.0966\n",
      "Epoch 8/10\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.9981 - val_loss: 1.1073\n",
      "Epoch 9/10\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.9778 - val_loss: 1.1117\n",
      "Epoch 10/10\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.9745 - val_loss: 1.1185\n",
      "\u001b[1m1412/1412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 799us/step\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\estel\\Documents\\Apprentissage\\Datascientest\\Projet\\feb24_bds_accidents\\venv\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Users\\estel\\Documents\\Apprentissage\\Datascientest\\Projet\\feb24_bds_accidents\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1.1883 - val_loss: 1.1131\n",
      "Epoch 2/10\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1.0857 - val_loss: 1.0845\n",
      "Epoch 3/10\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.0703 - val_loss: 1.0867\n",
      "Epoch 4/10\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1.0532 - val_loss: 1.0792\n",
      "Epoch 5/10\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.0455 - val_loss: 1.0805\n",
      "Epoch 6/10\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1.0356 - val_loss: 1.0892\n",
      "Epoch 7/10\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.0151 - val_loss: 1.0785\n",
      "Epoch 8/10\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1.0068 - val_loss: 1.0869\n",
      "Epoch 9/10\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.9995 - val_loss: 1.0854\n",
      "Epoch 10/10\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.9856 - val_loss: 1.1010\n",
      "\u001b[1m1412/1412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 770us/step\n"
     ]
    }
   ],
   "source": [
    "score = cross_val_score(model, X_train, y_train, scoring=scorer, cv=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores :  [0.56067316 0.57302276]\n"
     ]
    }
   ],
   "source": [
    "print(\"Scores : \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\estel\\Documents\\Apprentissage\\Datascientest\\Projet\\feb24_bds_accidents\\venv\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Users\\estel\\Documents\\Apprentissage\\Datascientest\\Projet\\feb24_bds_accidents\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.2752 - val_loss: 1.1657\n",
      "Epoch 2/10\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1347 - val_loss: 1.1227\n",
      "Epoch 3/10\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0999 - val_loss: 1.1308\n",
      "Epoch 4/10\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0583 - val_loss: 1.1317\n",
      "Epoch 5/10\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0354 - val_loss: 1.1210\n",
      "Epoch 6/10\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0299 - val_loss: 1.1547\n",
      "Epoch 7/10\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9924 - val_loss: 1.1256\n",
      "Epoch 8/10\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9823 - val_loss: 1.1428\n",
      "Epoch 9/10\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9562 - val_loss: 1.1529\n",
      "Epoch 10/10\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9237 - val_loss: 1.1629\n",
      "\u001b[1m353/353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\estel\\Documents\\Apprentissage\\Datascientest\\Projet\\feb24_bds_accidents\\venv\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Users\\estel\\Documents\\Apprentissage\\Datascientest\\Projet\\feb24_bds_accidents\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.2624 - val_loss: 1.1562\n",
      "Epoch 2/10\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1215 - val_loss: 1.1183\n",
      "Epoch 3/10\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0913 - val_loss: 1.1128\n",
      "Epoch 4/10\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0581 - val_loss: 1.1252\n",
      "Epoch 5/10\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0312 - val_loss: 1.1546\n",
      "Epoch 6/10\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0122 - val_loss: 1.1330\n",
      "Epoch 7/10\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9816 - val_loss: 1.1596\n",
      "Epoch 8/10\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9607 - val_loss: 1.1524\n",
      "Epoch 9/10\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9449 - val_loss: 1.1678\n",
      "Epoch 10/10\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9423 - val_loss: 1.1841\n",
      "\u001b[1m353/353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 967us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.70      0.63      5645\n",
      "           2       0.50      0.54      0.52      5645\n",
      "           3       0.37      0.32      0.34      5646\n",
      "           4       0.42      0.33      0.37      5645\n",
      "\n",
      "    accuracy                           0.47     22581\n",
      "   macro avg       0.46      0.47      0.46     22581\n",
      "weighted avg       0.46      0.47      0.46     22581\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = cross_val_predict(model, X_test, y_test, cv=2)\n",
    "report = classification_report(y_test, predicted)\n",
    "\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Réseau Profond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_deep_neural_network(input_shape, num_classes):\n",
    "    model = models.Sequential(\n",
    "        [\n",
    "            layers.Flatten(\n",
    "                input_shape=input_shape\n",
    "            ),  # Flatten transforme l'entrée en un vecteur 1D\n",
    "            layers.Dense(\n",
    "                512, activation=\"relu\"\n",
    "            ),  # Première couche dense avec 512 neurones et activation ReLU\n",
    "            layers.Dropout(0.2),  # Dropout pour la régularisation\n",
    "            layers.Dense(\n",
    "                256, activation=\"relu\"\n",
    "            ),  # Deuxième couche dense avec 256 neurones et activation ReLU\n",
    "            layers.Dropout(0.2),  # Dropout pour la régularisation\n",
    "            layers.Dense(\n",
    "                128, activation=\"relu\"\n",
    "            ),  # Troisième couche dense avec 128 neurones et activation ReLU\n",
    "            layers.Dense(\n",
    "                num_classes, activation=\"softmax\"\n",
    "            ),  # Couche de sortie avec le nombre de classes et activation softmax\n",
    "        ]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (48,)  # A adapter selon le df choisi, 15 vars ou +\n",
    "num_classes = 4  # Classes en sortie\n",
    "deep_model = create_deep_neural_network(input_shape, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_model.compile(\n",
    "    optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_model = deep_model.fit(X_train, y_train, epochs=80, batch_size=32, verbose=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
